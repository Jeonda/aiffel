{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어 데이터 챗봇 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - RNN 기반 LSTM등의 모델로 챗봇을 구현해왔다. 이번에는 트랜스포머라는 모델을 활용하여 챗봇을 구현해보자\n",
    " - 트랜스포머 모델을 기반으로 한 인코더-디코더 구조\n",
    "\n",
    "  - 트랜스포머의 인코더 디코더 구조 이해하기\n",
    "  - 내부 단어 토크나이저 사용하기 \n",
    "  - 셀프 어텐션 이해하기\n",
    "  - 한국어에도 적용해보기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./img/ex.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행의 크기가 50, 열의 크기가 512인 행렬을 그려봅시다. 이를테면, 최대 문장의 길이가 50이고 워드 임베딩 차원을 512로 하는 모델의 입력 벡터 모양이 이와 같을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일드 닷 프로덕트 어텐션 함수를 구현해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  \"\"\"어텐션 가중치를 계산. \"\"\"\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # add the mask to zero out padding tokens\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "멀티 헤드 어텐션을 구현하면 다음과 같습니다.\n",
    "\n",
    "내부적으로는 스케일드 닷 프로덕트 어테션 함수를 호출합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # linear layers\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # final linear layer\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마스킹(Masking)이란, 특정 값들을 가려서 실제 연산에 방해가 되지 않도록 하는 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더\n",
    "\n",
    "하나의 인코더 층은 크게 총 2개의 서브 층(sublayer)으로 나누어집니다.\n",
    "바로 셀프 어텐션과 피드 포워드 신경망입니다. 셀프 어텐션은 멀티 헤드 어텐션으로 병렬적으로 이루어집니다.\n",
    "\n",
    "두 개의 서브 층을 가지는 하나의 인코더 층을 구현하는 함수는 다음과 같습니다. 함수 내부적으로 첫 번째 서브 층와 두 번째 서브 층을 구현하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더 층을 쌓아 인코더 만들기\n",
    "이렇게 구현한 인코더 층을 임베딩 층(Embedding layer)과 포지셔널 인코딩(Positional Encoding)을 연결하고, 사용자가 원하는 만큼 인코더 층을 쌓음으로써 트랜스포머의 인코더가 완성됩니다.\n",
    "\n",
    "인코더와 디코더 내부에서는 각 서브층 이후에 훈련을 돕는 Layer Normalization이라는 테크닉이 사용되었습니다. 위 그림에서는 Normalize라고 표시된 부분에 해당됩니다.\n",
    "\n",
    "트랜스포머는 하이퍼파라미터인 num_layers 개수의 인코더 층을 쌓습니다. 논문에서는 총 6개의 인코더 층을 사용하였지만, 실습에서는 학습 시간을 고려하여 그보다 적은 개수를 사용할 예정입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더\n",
    "디코더는 인코더와 비슷하지만, 인코더보다 조금 더 복잡합니다. 인코더는 두 개의 서브 층으로 구성되지만, 디코더는 세 개의 서브 층으로 구성된다는 점이 다릅니다.\n",
    "첫 번째는 셀프 어텐션, 두 번째는 인코더-디코더 어텐션, 세 번째는 피드 포워드 신경망입니다. 인코더-디코더 어텐션은 셀프 어텐션과는 달리, Query가 디코더의 벡터인 반면에 Key와 Value가 인코더의 벡터라는 특징이 있습니다. 이 부분이 인코더가 입력 문장으로부터 정보를 디코더에 전달하는 과정입니다.\n",
    "인코더의 셀프 어텐션과 마찬가지로 디코더의 셀프 어텐션, 인코더-디코더 어텐션 두 개의 어텐션 모두 스케일드 닷 프로덕트 어텐션을 멀티 헤드 어텐션으로 병렬적으로 수행합니다.\n",
    "\n",
    "디코더의 세 개의 서브 층을 내부적으로 구현한 디코더의 함수는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더 층을 쌓아 디코더 만들기\n",
    "이렇게 구현한 디코더의 층은 임베딩 층(Embedding layer)과 포지셔널 인코딩(Positional Encoding)을 연결하고, 사용자가 원하는 만큼 디코더 층을 쌓아 트랜스포머의 디코더가 완성됩니다.\n",
    "\n",
    "인코더와 마찬가지로 num_layers 개수의 디코더 층을 쌓습니다. 논문에서는 총 6개의 디코더 층을 사용하였지만, 실습에서는 학습 시간을 고려하여 그보다 적은 개수를 사용할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "    # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기\n",
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다.\n",
    "\n",
    "이 데이터는 아래의 링크에서 다운로드할 수 있습니다.\n",
    "\n",
    "$ wget https://github.com/songys/Chatbot_data/raw/master/ChatbotData%20.csv\n",
    "\n",
    "\n",
    "데이터를 받아오는 이번 스텝에서 목표로 하는 것은 다음과 같습니다.\n",
    "\n",
    "정해진 개수인 50,000개의 질문과 답변의 쌍을 추출한다.\n",
    "문장에서 단어와 구두점 사이에 공백을 추가한다.\n",
    "알파벳과 ! ? , . 이 4개의 구두점을 제외하고 다른 특수문자는 모두 제거한다.\n",
    "데이터를 다운로드해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#path_to_zip = tf.keras.utils.get_file(\n",
    "#    'cornell_movie_dialogs.zip',\n",
    "#    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "#    extract=True)\n",
    "\n",
    "\n",
    "#path_to_dataset = os.path.join(\n",
    "#    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기\n",
    "영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있습니다.\n",
    "\n",
    "이번 전처리는 정규 표현식(Regular Expression)을 사용하여 구두점(punctuation)을 제거하여 단어를 토크나이징(tokenizing)하는 일에 방해가 되지 않도록 정제하는 것을 목표로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "print(\"슝=3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "  id2line = {}\n",
    "  with open(path_to_movie_lines, errors='ignore') as file:\n",
    "    lines = file.readlines()\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    id2line[parts[0]] = parts[4]\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(path_to_movie_conversations, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "    for i in range(len(conversation) - 1):\n",
    "            # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "\n",
    "      if len(inputs) >= MAX_SAMPLES:\n",
    "        return inputs, outputs\n",
    "  return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 50000\n",
      "전체 샘플 수 : 50000\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: she s not a . . .\n",
      "전처리 후의 22번째 답변 샘플: lesbian ? no . i found a picture of jared leto in one of her drawers , so i m pretty sure she s not harboring same sex tendencies .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기\n",
    "\n",
    " - 한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. \n",
    " - 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용해보세요.\n",
    "\n",
    "\n",
    "병렬 데이터 전처리하기\n",
    "질문과 답변의 셋을 각각 questions와 answers에 저장하였으므로, 본격적으로 전처리를 진행해보겠습니다. 이번 스텝에서 진행할 전체적인 과정을 요약하면 다음과 같습니다.\n",
    "\n",
    "TensorFlow Datasets SubwordTextEncoder를 토크나이저로 사용한다.  단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,  각 토큰을 고유한 정수로 인코딩한다.\n",
    "각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
    "최대 길이 MAX_LENGTH인 40을 넘는 문장들은 필터링한다.\n",
    "MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 단어장(Vocabulary) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2ceae88340dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# (주의) Tensorflow 2.3.0 이상의 버전에서는 아래 주석의 코드를 대신 실행해 주세요.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubwordTextEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_from_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"슝=3 \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36mbuild_from_corpus\u001b[0;34m(cls, corpus_generator, target_vocab_size, max_subword_length, max_corpus_chars, reserved_tokens)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# Another option could be to do a binary search over *ranks* of the tokens.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_token_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_binary_search\u001b[0;34m(min_token_count, max_token_count)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_token_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_min\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0;31m# Return the one that's closest to the target_vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_binary_search\u001b[0;34m(min_token_count, max_token_count)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_token_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_min\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0;31m# Return the one that's closest to the target_vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_binary_search\u001b[0;34m(min_token_count, max_token_count)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_token_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_min\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0;31m# Return the one that's closest to the target_vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_binary_search\u001b[0;34m(min_token_count, max_token_count)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_token_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_min\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0;31m# Return the one that's closest to the target_vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_binary_search\u001b[0;34m(min_token_count, max_token_count)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_token_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_min\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0;31m# Return the one that's closest to the target_vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_binary_search\u001b[0;34m(min_token_count, max_token_count)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_token_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_min\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0;31m# Return the one that's closest to the target_vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_binary_search\u001b[0;34m(min_token_count, max_token_count)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_token_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_min\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0;31m# Return the one that's closest to the target_vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_binary_search\u001b[0;34m(min_token_count, max_token_count)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_token_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mnext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_token_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_min\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0;31m# Return the one that's closest to the target_vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_binary_search\u001b[0;34m(min_token_count, max_token_count)\u001b[0m\n\u001b[1;32m    301\u001b[0m           \u001b[0mreserved_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreserved_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m           \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m           max_subword_length=max_subword_length)\n\u001b[0m\u001b[1;32m    304\u001b[0m       \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_build_from_token_counts\u001b[0;34m(cls, token_counts, min_token_count, reserved_tokens, num_iterations, max_subword_length)\u001b[0m\n\u001b[1;32m    344\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_to_subwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m           \u001b[0mlast_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax_subword_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mend_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_token_to_subwords\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    194\u001b[0m           min(len(token), start + self._max_subword_len), start, -1):\n\u001b[1;32m    195\u001b[0m         \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         if (candidate in self._subword_to_id or\n\u001b[0m\u001b[1;32m    197\u001b[0m             candidate == _UNDERSCORE_REPLACEMENT):\n\u001b[1;32m    198\u001b[0m           \u001b[0msubword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.2.0 이하)\n",
    "#tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# (주의) Tensorflow 2.3.0 이상의 버전에서는 아래 주석의 코드를 대신 실행해 주세요. \n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교사 강요(Teacher Forcing) 사용하기\n",
    "tf.data.Dataset API는 훈련 프로세스의 속도가 빨라지도록 입력 파이프라인을 구축하는 API입니다.\n",
    "\n",
    "이를 적극 사용하기 위해서 질문과 답변의 쌍을 tf.data.Dataset의 입력으로 넣어주는 작업을 합니다.\n",
    "\n",
    "이때, 디코더의 입력과 실제값(레이블)을 정의해주기 위해서는 교사 강요(Teacher Forcing)이라는 언어 모델의 훈련 기법을 이해해야만 합니다. 아래의 글을 통해 교사 강요에 대해 알아봅시다. (모두 읽을 필요는 없고, 교사 강요 부분까지만 읽어도 됩니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성합니다. 이때, 교사 강요를 위해서 answers[:, :-1]를 디코더의 입력값, answers[:, 1:]를 디코더의 레이블로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기\n",
    "모델 정의 및 학습하기\n",
    "이제 앞서 사용한 인코더 층 함수와 디코더 층 함수를 사용하여 트랜스포머 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "\t# 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실 함수(Loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 커스텀된 학습률(Learning rate)\n",
    "딥러닝 모델학습 시 learning rate는 매우 중요한 하이퍼파라미터입니다. 최근에는 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용하고 있습니다. 이런 방법을 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)이라고 합니다.\n",
    "\n",
    "논문에 나온 공식을 참고하여 커스텀 학습률 스케줄러를 통한 아담 옵티마이저를 사용합니다. 논문에 나온 공식은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가하기\n",
    " - Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다.\n",
    " \n",
    " \n",
    "예측(inference) 단계는 기본적으로 다음과 같은 과정을 거칩니다.\n",
    "새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다.\n",
    "위의 과정을 모두 담은 decoder_inference() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('공부는 끝이 없어')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 루브릭\n",
    "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.\n",
    " - 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
    "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.\n",
    " - 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.\n",
    "3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.\n",
    " - 한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
