{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confident-beatles",
   "metadata": {},
   "source": [
    "# Fashin GAN 학습하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proof-timber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow 2.2.0\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"tensorflow\", tf.__version__)\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_x, _), (test_x, _) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max pixel:\", train_x.max())\n",
    "print(\"min pixel:\", train_x.min())\n",
    "\n",
    "train_x = (train_x - 127.5) / 127.5 # 이미지를 [-1, 1]로 정규화합니다.\n",
    "\n",
    "print(\"max pixel:\", train_x.max())\n",
    "print(\"min pixel:\", train_x.min())\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0], 28, 28, 1).astype('float32')\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_x[0].reshape(28, 28), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(train_x[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'index: {i}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 12))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    random_index = np.random.randint(1, 60000)\n",
    "    plt.imshow(train_x[random_index].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'index: {random_index}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_x).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-occasions",
   "metadata": {},
   "source": [
    "# 생성자 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "\n",
    "    # Start\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # First: Dense layer\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Second: Reshape layer\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "\n",
    "    # Third: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(128, kernel_size=(5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Fourth: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Fifth: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(1, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False, \\\n",
    "                                     activation='tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generator(noise, training=False)\n",
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-blank",
   "metadata": {},
   "source": [
    "# 판별자 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_discriminator_model():\n",
    "\n",
    "    # Start\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # First: Conv2D Layer\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Second: Conv2D Layer\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Third: Flatten Layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Fourth: Dense Layer\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = discriminator(generated_image, training=False)\n",
    "decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-bridge",
   "metadata": {},
   "source": [
    "# 손실함수(loss function)\n",
    " - GAN은 손실함수로 교차 엔트로피 사용 (Cross Entropy)\n",
    " - 점점 가까워지기 원하는 두 값이 얼마나 큰 차이가 나는지 정량적 계산\n",
    " - Real Image에 대한 라벨 1, Fake Image에 대한 라벨 0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = [[1, 2, 3],\n",
    "          [4, 5, 6]]\n",
    "\n",
    "tf.ones_like(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-nothing",
   "metadata": {},
   "source": [
    "## generator_loss\n",
    " - Generator loss는 fake output이 1에 가까워지기를 바라므로 tk.ones_like와의 교차 엔트로피값 계산하면 됨\n",
    " - cross_entropy 값은 fake output이 1에 가까울수록 작은값을 가지게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-steering",
   "metadata": {},
   "source": [
    "## discriminator_loss\n",
    " - discriminator loss는 real output값이 1에 가까워지기를, fake output은 0에 가까워지기를 바라므로\n",
    " - 두가지 loss값을 모두 계산해야함. \n",
    " - real output은 1로 채워진 벡터와, fake output은 0으로 채워진 벡터와 비교해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-completion",
   "metadata": {},
   "source": [
    "## discriminator accuracy\n",
    " - 판별자가 얼마나 정확한지 accuracy 계산. \n",
    " - 이상적인것은 fake output과 real output이 초반에는 1.0에 가깝게 나오다가 서서히 낮아져서 둘다 0.5에 가까운것\n",
    " - fake accuracy가 1.0에 더 가깝다면 아직은 생성자가 판별자를 충분히 잘 속이지 못하고 있다는 뜻\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_accuracy(real_output, fake_output):\n",
    "    real_accuracy = tf.reduce_mean(tf.cast(tf.math.greater_equal(real_output, tf.constant([0.5])), tf.float32))\n",
    "    fake_accuracy = tf.reduce_mean(tf.cast(tf.math.less(fake_output, tf.constant([0.5])), tf.float32))\n",
    "    return real_accuracy, fake_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-statement",
   "metadata": {},
   "source": [
    "# Optimizer 최적화 함수\n",
    " - Adam 최적화 기법 사용\n",
    " - learning rate 는 0.0001로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-calculator",
   "metadata": {},
   "source": [
    "## 샘플 확인\n",
    " - 한번에 16장 생성, seed 노이즈를 만들어둬야 진전과정 확인 \n",
    " - 100차원 노이즈를 총 16개 형상의 벡터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "seed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-prior",
   "metadata": {},
   "source": [
    "# 훈련과정 설계\n",
    " - mini batch당 진행할 train_step 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):  #(1) 입력데이터 Real Image 역할을 할 image 한 세트를 입력으로 받음\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])  #(2) 생성자 입력 노이즈\n",
    "    # 생성자 입력 노이즈 : generator가 Fake Image를 생성하기 위한 noise를 image 한 세트와 같은 크기인 \n",
    "    # Batch_size 만큼 생성함\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:  #(3) tf.GradientTape() 오픈\n",
    "        #tf.GradientTape()는 가중치 갱신을 위한 Gradient를 자동 미분으로 계산하기 위해 with 구문 열기\n",
    "        generated_images = generator(noise, training=True)  #(4) generated_images 생성\n",
    "        #generated_images 생성 : generator가 noise를 입력받은 후 generated_images 생성\n",
    "\n",
    "        #(5) discriminator 판별\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        #discriminator 판별 : discriminator가 Real Image인 images와 Fake Image인 generated_images를 각각 입력받은 후 real_output, fake_output 출력\n",
    "\n",
    "        #(6) loss 계산\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        #loss 계산 : fake_output, real_output으로 generator와 discriminator 각각의 loss 계산\n",
    "        #(7) accuracy 계산\n",
    "        real_accuracy, fake_accuracy = discriminator_accuracy(real_output, fake_output) \n",
    "        #accuracy 계산 : fake_output, real_output으로 discriminator가\n",
    "    \n",
    "    #(8) gradient 계산\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    #gradient 계산 : gen_tape와 disc_tape를 활용해 gradient를 자동으로 계산\n",
    "\n",
    "    #(9) 모델 학습\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    # 모델 학습 : 계산된 gradient를 optimizer에 입력해 가중치 갱신\n",
    "    return gen_loss, disc_loss, real_accuracy, fake_accuracy  #(10) 리턴값 \n",
    "    # 리턴값 : 이번 스텝에 계산된 loss와 accuracy를 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-launch",
   "metadata": {},
   "source": [
    "## 샘플 생성 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, it, sample_seeds):\n",
    "\n",
    "    predictions = model(sample_seeds, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('{}/aiffel/dcgan_newimage/fashion/generated_samples/sample_epoch_{:04d}_iter_{:03d}.png'\n",
    "                    .format(os.getenv('HOME'), epoch, it))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-corner",
   "metadata": {},
   "source": [
    "## 학습진행과정 확인, loss / accuracy 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6    # matlab 차트의 기본 크기를 15,6으로 지정해 줍니다.\n",
    "\n",
    "def draw_train_history(history, epoch):\n",
    "    # summarize history for loss  \n",
    "    plt.subplot(211)  \n",
    "    plt.plot(history['gen_loss'])  \n",
    "    plt.plot(history['disc_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('batch iters')  \n",
    "    plt.legend(['gen_loss', 'disc_loss'], loc='upper left')  \n",
    "\n",
    "    # summarize history for accuracy  \n",
    "    plt.subplot(212)  \n",
    "    plt.plot(history['fake_accuracy'])  \n",
    "    plt.plot(history['real_accuracy'])  \n",
    "    plt.title('discriminator accuracy')  \n",
    "    plt.ylabel('accuracy')  \n",
    "    plt.xlabel('batch iters')  \n",
    "    plt.legend(['fake_accuracy', 'real_accuracy'], loc='upper left')  \n",
    "    \n",
    "    # training_history 디렉토리에 epoch별로 그래프를 이미지 파일로 저장합니다.\n",
    "    plt.savefig('{}/aiffel/dcgan_newimage/fashion/training_history/train_history_{:04d}.png'\n",
    "                    .format(os.getenv('HOME'), epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/dcgan_newimage/fashion/training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-bubble",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, save_every):\n",
    "    start = time.time()\n",
    "    history = {'gen_loss':[], 'disc_loss':[], 'real_accuracy':[], 'fake_accuracy':[]}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        for it, image_batch in enumerate(dataset):\n",
    "            gen_loss, disc_loss, real_accuracy, fake_accuracy = train_step(image_batch)\n",
    "            history['gen_loss'].append(gen_loss)\n",
    "            history['disc_loss'].append(disc_loss)\n",
    "            history['real_accuracy'].append(real_accuracy)\n",
    "            history['fake_accuracy'].append(fake_accuracy)\n",
    "\n",
    "            if it % 50 == 0:\n",
    "                display.clear_output(wait=True)\n",
    "                generate_and_save_images(generator, epoch+1, it+1, seed)\n",
    "                print('Epoch {} | iter {}'.format(epoch+1, it+1))\n",
    "                print('Time for epoch {} : {} sec'.format(epoch+1, int(time.time()-epoch_start)))\n",
    "\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epochs, it, seed)\n",
    "        print('Time for training : {} sec'.format(int(time.time()-start)))\n",
    "\n",
    "        draw_train_history(history, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_every = 5\n",
    "EPOCHS = 50\n",
    "\n",
    "# 사용가능한 GPU 디바이스 확인\n",
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(train_dataset, EPOCHS, save_every)\n",
    "\n",
    "# 학습과정의 loss, accuracy 그래프 이미지 파일이 ~/aiffel/dcgan_newimage/fashion/training_history 경로에 생성되고 있으니\n",
    "# 진행 과정을 수시로 확인해 보시길 권합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-nylon",
   "metadata": {},
   "source": [
    "# STEP 1. 데이터셋 구성하기\n",
    " - 학습에 사용할 train_x의 이미지를 [-1, 1]로 정규화합니다.\n",
    " - 로드한 학습 데이터를 시각화를 통해 확인해 봅시다.\n",
    " - tf.data.Dataset 모듈의 fromtensorslices() 함수를 사용하여 미니배치 데이터셋을 구성해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "(train_x, _), (test_x, _) = cifar10.load_data()\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-baseball",
   "metadata": {},
   "source": [
    "# STEP 2. 생성자 모델 구현하기\n",
    " - (32, 32, 3)의 shape를 가진 이미지를 생성하는 생성자 모델 구현 함수를 작성해 봅시다.\n",
    " - noise = tf.random.normal([1, 100])로 생성된 랜덤 노이즈를 입력으로 하여 방금 구현한 생성자로 랜덤 이미지를 생성해 봅시다.\n",
    " - 생성된 랜덤 이미지가 생성자 출력 규격에 잘 맞는지 확인해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-innocent",
   "metadata": {},
   "source": [
    "# STEP 3. 판별자 모델 구현하기\n",
    " - (32, 32, 3)의 이미지를 입력으로 받아 1dim을 판별결과를 출력하는 판별자 모델 구현 함수를 작성해 봅시다.\n",
    " - 위 STEP 2에서 생성한 랜덤 이미지를 판별자 모델이 판별한 결과값을 확인해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-private",
   "metadata": {},
   "source": [
    "# STEP 4. 손실함수와 최적화 함수 구현하기\n",
    " - 생성자와 판별자의 손실함수(loss)를 구현해 봅시다.\n",
    " - 판별자의 출력값을 가지고 실제/생성(real/fake) 이미지 판별 정확도(accuracy)를 계산하는 함수를 구현해 봅시다.\n",
    " - 생성자와 판별자를 최적화하는 optimizer를 정의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-pound",
   "metadata": {},
   "source": [
    "# STEP 5. 훈련과정 상세 기능 구현하기\n",
    " - 1개 미니배치의 훈련 과정을 처리하는 train_step() 함수를 구현해 봅시다.\n",
    " - 16개의 고정된 seed를 입력으로 하여 훈련 과정 동안 생성한 이미지를 시각화하는 generate_and_save_images() 함수를 구현해 봅시다.\n",
    " - 훈련 epoch마다 생성자/판별자의 loss 및 판별자의 실제/생성(real/fake) 이미지 판별 accuracy 히스토리(history)를 그래프로 시각화하는 draw_train_history() 함수를 구현해 봅시다.\n",
    " - training_checkpoints 디렉토리에 몇 epoch마다 모델을 저장하는 checkpoint 모듈을 설정해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-desert",
   "metadata": {},
   "source": [
    "# STEP 6. 학습 과정 진행하기\n",
    " - 위 STEP 5에서 구현한 기능들을 활용하여 최소 50 epoch만큼의 모델 학습을 진행해 봅시다.\n",
    " - 학습 과정에서 생성된 샘플 이미지로 만든 gif 파일을 통해 학습 진행 과정을 시각적으로 표현해 봅시다.\n",
    " - 학습 과정을 담은 샘플 이미지, gif 파일, 학습 진행 그래프 이미지를 함께 제출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-syndication",
   "metadata": {},
   "source": [
    "# STEP 7. (optional) GAN 훈련 과정 개선하기\n",
    " - STEP 6을 진행하면서 생성된 샘플 이미지, 학습 과정 그래프 등을 통해 이전 훈련 과정의 문제점을 분석해 봅시다.\n",
    " - 모델구조 또는 학습 과정을 개선한 내역과 그 결과(샘플 이미지, 학습 과정 그래프 포함)를 함께 제출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-protocol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epooch 추가 진행\n",
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/dcgan_newimage/cifar10/training_checkpoints'\n",
    "\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "checkpoint.restore(latest)\n",
    "\n",
    "generator = checkpoint.generator\n",
    "discriminator = checkpoint.discriminator\n",
    "\n",
    "# 로드한 모델이 정상적으로 이미지를 생성하는지 확인해 봅니다. \n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "np_generated = generated_image.numpy()\n",
    "np_generated = (np_generated * 127.5) + 127.5   # reverse of normalization\n",
    "np_generated = np_generated.astype(int)\n",
    "plt.imshow(np_generated[0])\n",
    "plt.show()  # 정상적으로 모델이 로드되었다면 랜덤 이미지가 아니라 CIFAR-10 이미지가 그려질 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-movie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-logan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
