{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [GD14]Video_app_kalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoClip, VideoFileClip\n",
    "from moviepy.editor import ipython_display\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 0/404 [00:00<?, ?it/s, now=None]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/aiffel/aiffel/video_sticker_app/images/mvpyresult.mp4.\n",
      "MoviePy - Writing audio in mvpyresultTEMP_MPY_wvf_snd.mp3\n",
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/aiffel/aiffel/video_sticker_app/images/mvpyresult.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/aiffel/aiffel/video_sticker_app/images/mvpyresult.mp4\n"
     ]
    }
   ],
   "source": [
    "# 읽기\n",
    "video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/video2.mp4'\n",
    "clip = VideoFileClip(video_path)\n",
    "clip = clip.resize(width=640)\n",
    "clip.ipython_display(fps=30, loop=True, autoplay=True, rd_kwargs=dict(logger=None))\n",
    "\n",
    "# 쓰기\n",
    "result_video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/mvpyresult.mp4'\n",
    "clip.write_videofile(result_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|█▏        | 50/403 [00:00<00:00, 493.09it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/aiffel/aiffel/video_sticker_app/images/mvpyresult2.mp4.\n",
      "Moviepy - Writing video /home/aiffel/aiffel/video_sticker_app/images/mvpyresult2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/aiffel/aiffel/video_sticker_app/images/mvpyresult2.mp4\n"
     ]
    }
   ],
   "source": [
    "# 읽기\n",
    "video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/video2.mp4'\n",
    "clip = VideoFileClip(video_path)\n",
    "clip = clip.resize(width=640)\n",
    "clip.ipython_display(fps=30, loop=True, autoplay=True, rd_kwargs=dict(logger=None))\n",
    "\n",
    "# clip 에서 numpy 로 데이터 추출  ,ㅂㅏㄹㄱㄱㅣ 50% down\n",
    "vlen = int(clip.duration*clip.fps)\n",
    "video_container = np.zeros((vlen, clip.size[1], clip.size[0], 3), dtype=np.uint8)\n",
    "for i in range(vlen):\n",
    "    img = clip.get_frame(i/clip.fps)\n",
    "    video_container[i] = (img * 0.5).astype(np.uint8)\n",
    "\n",
    "# 새 clip 만들기\n",
    "dur = vlen / clip.fps\n",
    "outclip = VideoClip(lambda t: video_container[int(round(t*clip.fps))], duration=dur)\n",
    "\n",
    "# 쓰기\n",
    "result_video_path2 = os.getenv('HOME')+'/aiffel/video_sticker_app/images/mvpyresult2.mp4'\n",
    "outclip.write_videofile(result_video_path2, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|█▏        | 48/403 [00:00<00:00, 384.00it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/aiffel/aiffel/video_sticker_app/images/mvpyresult.mp4.\n",
      "Moviepy - Writing video /home/aiffel/aiffel/video_sticker_app/images/mvpyresult.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/aiffel/aiffel/video_sticker_app/images/mvpyresult.mp4\n",
      "[INFO] moviepy time : 2.76ms\n"
     ]
    }
   ],
   "source": [
    "# CASE 1 : moviepy 사용 read/write time\n",
    "start = cv2.getTickCount()\n",
    "clip = VideoFileClip(video_path)\n",
    "clip = clip.resize(width=640)\n",
    "\n",
    "vlen = int(clip.duration*clip.fps)\n",
    "video_container = np.zeros((vlen, clip.size[1], clip.size[0], 3), dtype=np.uint8)\n",
    "\n",
    "for i in range(vlen):\n",
    "    img = clip.get_frame(i/clip.fps)\n",
    "    video_container[i] = (img * 0.5).astype(np.uint8)\n",
    "\n",
    "dur = vlen / clip.fps\n",
    "outclip = VideoClip(lambda t: video_container[int(round(t*clip.fps))], duration=dur)\n",
    "\n",
    "mvpy_video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/mvpyresult.mp4'\n",
    "outclip.write_videofile(mvpy_video_path, fps=30)\n",
    "\n",
    "time = (cv2.getTickCount() - start) / cv2.getTickFrequency()\n",
    "print (f'[INFO] moviepy time : {time:.2f}ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] cv time : 1.53ms\n"
     ]
    }
   ],
   "source": [
    "# CASE 2 : OpenCV 사용  // read/write time\n",
    "start = cv2.getTickCount()\n",
    "vc = cv2.VideoCapture(video_path)\n",
    "\n",
    "cv_video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/cvresult.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "vw = cv2.VideoWriter(cv_video_path, fourcc, 30, (640,360))\n",
    "\n",
    "vlen = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "for i in range(vlen):\n",
    "    ret, img = vc.read()\n",
    "    if ret == False: break\n",
    "    \n",
    "    img_result = cv2.resize(img, (640, 360)) * 0.5\n",
    "    vw.write(img_result.astype(np.uint8))\n",
    "    \n",
    "time = (cv2.getTickCount() - start) / cv2.getTickFrequency()\n",
    "print (f'[INFO] cv time : {time:.2f}ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 루브릭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- moviepy 를 이용할 때의 장단점을 분석해 봅시다. 주피터 노트북에 답변을 작성해 코드와 함께 제출해 주세요.\n",
    " * MoviePy 특징\n",
    "   + 간단하며 직관적임\n",
    "   + Flexible함\n",
    "   + Protable함\n",
    "   + numpy와의 호환성\n",
    "   + 단점으로는 stream video에 대한 작업엔 적합하지 않습니다. 또 비디오의 개수가 많을 경우(100개 이상) 적합하지 않습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 웹캠을 통한 스티커앱을 실행하고 다각도로 문제점을 분석하여 보았다.\n",
    " - 거리, 인원수, 각도 등 다양한 측면에서의 문제점과 기술적 대안을 정리하였다.\n",
    "2. 스티커앱 초기버전이 가진 예외사항들을 분석하여 수정하였다. \n",
    " - 프레임 좌표범위 예외처리 관련 오류를 수정하였다.\n",
    "3. 칼만 필터를 웹캠 스티커앱에 적용하여 스티커의 안정성을 높여 보았다.\n",
    " - 칼만 필터를 적용한 스티커앱을 작성하여 실행해 보고 안정성 여부를 확인하였다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 첫번째 사진 \n",
    " - 거리, 각도, 프레임 벗어나면 잘 안됨\n",
    " - https://drive.google.com/file/d/1Htnx-FLIXjtbZApCNQDAj4wXRCQWjEIE/view?usp=sharing\n",
    "<img width=\"80%\" src=\"https://user-images.githubusercontent.com/38655888/117322260-ce22a000-aec8-11eb-942e-8855cb86fbbf.gif\"/>\n",
    "2. 두번째 사진 \n",
    " - 거리, 각도, 프레임은 해결된듯하나 속도가 4배 느려짐\n",
    " - https://drive.google.com/file/d/1RvGALyKkgK1Qn9agmXt3DLsD9X14WyHh/view?usp=sharing\n",
    "<img width=\"80%\" src=\"https://user-images.githubusercontent.com/38655888/117322535-0de98780-aec9-11eb-8482-32f502cf1ec2.gif\"/>\n",
    "3. 세번째 사진 \n",
    " - 칼만필터 적용\n",
    " - https://drive.google.com/file/d/1mx5F8y0HaCGr4QCmr9qkMSTyAEa9-9T4/view?usp=sharing\n",
    "<img width=\"80%\" src=\"https://user-images.githubusercontent.com/38655888/117322680-2c4f8300-aec9-11eb-818c-dcb4884b134a.gif\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## webcam_sticker.py 내용\n",
    "## from kfaddsticker import img2sticker_kf 추가하여 img2sticker_kf 함수 사용\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "from newaddsticker import img2sticker\n",
    "from kfaddsticker import img2sticker_kf\n",
    "\n",
    "detector_hog = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor('./models/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "def main():\n",
    "    cv2.namedWindow('show', 0)\n",
    "    cv2.resizeWindow('show', 640, 360)\n",
    "\n",
    "    #vc = cv2.VideoCapture(0)\n",
    "    #vc = cv2.VideoCapture('rtmp://rtmp.streamaxia.com/streamaxia/c23CC6')   # XXXXXX 부분은 본인 어플리케이션에서 확인한 코드로 대체해 주세요. \n",
    "    vc = cv2.VideoCapture('./images/video2.mp4')\n",
    "    \n",
    "    img_sticker = cv2.imread('./images/king.png')\n",
    "\n",
    "    vlen = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print (vlen) # 웹캠은 video length 가 0 입니다.\n",
    "\n",
    "    # 정해진 길이가 없기 때문에 while 을 주로 사용합니다.\n",
    "    # for i in range(vlen):\n",
    "    while True:\n",
    "        ret, img = vc.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        start = cv2.getTickCount()\n",
    "        img = cv2.flip(img, 1)  # 보통 웹캠은 좌우 반전\n",
    "\n",
    "        # 스티커 메소드를 사용\n",
    "        #img_result = img2sticker(img, img_sticker.copy(), detector_hog, landmark_predictor)   \n",
    "        img_result = img2sticker_kf(img, img_sticker.copy(), detector_hog, landmark_predictor)   \n",
    "\n",
    "        time = (cv2.getTickCount() - start) / cv2.getTickFrequency() * 1000\n",
    "        print ('[INFO] time: %.2fms'%time)\n",
    "        \n",
    "        cv2.imshow('show', img_result)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## newaddsticker.py 내용\n",
    "## preprocess, detector, landmark 변경\n",
    "\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "def img2sticker(img_orig, img_sticker, detector_hog, landmark_predictor):\n",
    "    # preprocess\n",
    "    img_rgb = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # detector\n",
    "    dlib_rects = detector_hog(img_rgb, 0)\n",
    "    if len(dlib_rects) < 1:\n",
    "        return img_orig\n",
    "    \n",
    "    # landmark\n",
    "    list_landmarks = []\n",
    "    for dlib_rect in dlib_rects:\n",
    "        points = landmark_predictor(img_rgb, dlib_rect)\n",
    "        list_points = list(map(lambda p: (p.x, p.y), points.parts()))\n",
    "        list_landmarks.append(list_points)\n",
    "    \n",
    "    # head coord\n",
    "    for dlib_rect, landmark in zip(dlib_rects, list_landmarks):\n",
    "        x = landmark[30][0] # nose\n",
    "        y = landmark[30][1] - dlib_rect.width()//2\n",
    "        w = dlib_rect.width()\n",
    "        h = dlib_rect.width()\n",
    "        break\n",
    "    \n",
    "    img_sticker = cv2.resize(img_sticker, (w,h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    refined_x = x - w // 2\n",
    "    refined_y = y - h\n",
    "\n",
    "    if refined_y < 0:\n",
    "        img_sticker = img_sticker[-refined_y:]\n",
    "        refined_y = 0\n",
    "\n",
    "    ###\n",
    "    # TODO : x 축 예외처리 코드 추가\n",
    "    if refined_x < 0:\n",
    "        img_sticker = img_sticker[:, -refined_x:]\n",
    "        refined_x = 0\n",
    "    elif refined_x + img_sticker.shape[1] >= img_orig.shape[1]:\n",
    "        img_sticker = img_sticker[:, :-(img_sticker.shape[1]+refined_x-img_orig.shape[1])]\n",
    "    ###\n",
    "\n",
    "    img_bgr = img_orig.copy()\n",
    "    sticker_area = img_bgr[refined_y:refined_y+img_sticker.shape[0], refined_x:refined_x+img_sticker.shape[1]]\n",
    "\n",
    "    img_bgr[refined_y:refined_y+img_sticker.shape[0], refined_x:refined_x+img_sticker.shape[1]] = \\\n",
    "        cv2.addWeighted(sticker_area, 1.0, img_sticker, 0.7, 0)\n",
    "\n",
    "    return img_bgr\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
